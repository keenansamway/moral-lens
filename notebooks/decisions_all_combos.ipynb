{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc787a0c",
   "metadata": {},
   "source": [
    "## Query models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7719ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Configured API keys: HF_TOKEN, OPENAI_API_KEY, ANTHROPIC_API_KEY, GOOGLE_API_KEY, OPENROUTER_API_KEY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from moral_lens.dilemma import DilemmaRunner\n",
    "from moral_lens.judge import JudgeRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model_ids = [\n",
    "    # # # Standard models # # #\n",
    "\n",
    "    # \"gpt-4.1-2025-04-14\",\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4.1-nano-2025-04-14\",\n",
    "    # \"gpt-4o-2024-11-20\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    # \"gpt-4o-2024-05-13\",\n",
    "    # \"gpt-4o-mini-2024-07-18\",\n",
    "    # \"gpt-3.5-turbo-0125\",\n",
    "    # \"gpt-3.5-turbo-1106\",\n",
    "\n",
    "    # \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"google/gemini-2.0-flash-001\",\n",
    "    # \"google/gemini-2.0-flash-lite-001\",\n",
    "    # \"google/gemini-pro-1.5\",\n",
    "    # \"google/gemini-flash-1.5\",\n",
    "    # \"google/gemini-flash-1.5-8b\",\n",
    "\n",
    "    # \"meta-llama/llama-4-maverick\",\n",
    "    # \"meta-llama/llama-4-scout\",\n",
    "    # \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-405b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    # \"meta-llama/llama-3-70b-instruct\",\n",
    "    # \"meta-llama/llama-3-8b-instruct\",\n",
    "    # \"meta-llama/llama-2-70b-chat\",\n",
    "\n",
    "    # \"anthropic/claude-3.7-sonnet:beta\",\n",
    "    # \"anthropic/claude-3.5-sonnet:beta\",\n",
    "    # \"anthropic/claude-3.5-sonnet-20240620:beta\",\n",
    "    # \"anthropic/claude-3.5-haiku:beta\",\n",
    "    # \"anthropic/claude-3-sonnet:beta\",\n",
    "    # \"anthropic/claude-3-haiku:beta\",\n",
    "\n",
    "    # \"microsoft/phi-4\",\n",
    "    # \"microsoft/phi-3.5-mini-128k-instruct\",\n",
    "    # \"microsoft/phi-3-medium-128k-instruct\",\n",
    "    # \"microsoft/phi-3-mini-128k-instruct\",\n",
    "\n",
    "    # \"qwen/qwen-max\",\n",
    "    # \"qwen/qwen-plus\",\n",
    "    # \"qwen/qwen-turbo\",\n",
    "\n",
    "    # \"qwen/qwen-2.5-72b-instruct\",\n",
    "    # \"qwen/qwen-2.5-7b-instruct\",\n",
    "    # \"qwen/qwen-2-72b-instruct\",\n",
    "\n",
    "    # \"qwen/qwen3-32b:nothink\",\n",
    "    # \"qwen/qwen3-30b-a3b:nothink\",\n",
    "\n",
    "    # \"deepseek/deepseek-chat\",\n",
    "    # \"deepseek/deepseek-chat-v3-0324\",\n",
    "    # \"deepseek/deepseek-prover-v2\",\n",
    "\n",
    "    # \"google/gemma-3-27b-it\",\n",
    "    # \"google/gemma-3-12b-it\",\n",
    "    # \"google/gemma-3-4b-it\",\n",
    "\n",
    "    # \"google/gemma-2-27b-it\",\n",
    "    # \"google/gemma-2-9b-it\",\n",
    "\n",
    "    # \"cohere/command-r\",\n",
    "    # \"cohere/command-r-plus\",\n",
    "\n",
    "    # \"mistralai/mixtral-8x22b-instruct\",\n",
    "    # \"mistralai/mixtral-8x7b-instruct\",\n",
    "    # \"mistralai/mistral-7b-instruct-v0.3\",\n",
    "    # \"mistralai/mistral-7b-instruct-v0.1\",\n",
    "    # \"mistralai/mistral-nemo\",\n",
    "    # \"mistralai/mistral-small\",\n",
    "    # \"mistralai/mistral-large\",\n",
    "    # \"mistralai/mistral-large-2407\",\n",
    "\n",
    "    # \"amazon/nova-micro-v1\",\n",
    "    # \"amazon/nova-lite-v1\",\n",
    "    # \"amazon/nova-pro-v1\",\n",
    "\n",
    "\n",
    "    # # # Reasoning models # # #\n",
    "\n",
    "    # \"qwen/qwq-32b\",\n",
    "\n",
    "    # \"qwen/qwen3-32b:think\",\n",
    "    # \"qwen/qwen3-30b-a3b:think\",\n",
    "\n",
    "    # \"deepseek/deepseek-r1\",\n",
    "    # \"deepseek/deepseek-r1-distill-qwen-1.5b\",\n",
    "    # \"deepseek/deepseek-r1-distill-llama-8b\",\n",
    "    # \"deepseek/deepseek-r1-distill-llama-70b\",\n",
    "\n",
    "    # \"microsoft/phi-4-reasoning-plus\",\n",
    "\n",
    "    # \"x-ai/grok-3-mini-beta\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250522/all_combos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36934e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file already exists at data/20250522/all_combos/responses/qwen3-32b:nothink_s1.csv. Use `overwrite=True` in .run() to overwrite it.\n",
      "[INFO] Processed responses saved to data/20250522/all_combos/responses/qwen3-32b:nothink_s1.csv.\n",
      "Finished decision model qwen/qwen3-32b:nothink.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    # \"s2\",\n",
    "    # \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    for exp in exps:\n",
    "        dr = DilemmaRunner(\n",
    "            model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            override_decision_temperature=0.0,  # default 0.0\n",
    "            # prompts_template='reasoning_after',\n",
    "            prompts_template='no_reasoning',\n",
    "            choices_filename=\"choices_all_combos.csv\",\n",
    "        )\n",
    "        await dr.run(\n",
    "            # limit=10,\n",
    "            # disable_validation=True,\n",
    "            try_retries=False\n",
    "        )\n",
    "    print(f\"Finished decision model {decision_model_id}.\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moral2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
