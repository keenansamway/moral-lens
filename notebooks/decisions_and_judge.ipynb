{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7719ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Configured API keys: HF_TOKEN, OPENAI_API_KEY, ANTHROPIC_API_KEY, GOOGLE_API_KEY, OPENROUTER_API_KEY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from moral_lens.dilemma import DilemmaRunner\n",
    "from moral_lens.judge import JudgeRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc787a0c",
   "metadata": {},
   "source": [
    "## Query models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model_ids = [\n",
    "    # # # Standard Models # # #\n",
    "    \"gpt-4.1-2025-04-14\",\n",
    "    \"gpt-4.1-mini-2025-04-14\",\n",
    "    \"gpt-4.1-nano-2025-04-14\",\n",
    "    \"gpt-4o-2024-11-20\",\n",
    "    \"gpt-4o-2024-08-06\",\n",
    "    \"gpt-4o-2024-05-13\",\n",
    "    \"gpt-4o-mini-2024-07-18\",\n",
    "    \"gpt-3.5-turbo-0125\",\n",
    "    \"gpt-3.5-turbo-1106\",\n",
    "    # \"gpt-3.5-turbo-0613\", # depricated\n",
    "\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    \"google/gemini-2.0-flash-001\",\n",
    "    \"google/gemini-2.0-flash-lite-001\",\n",
    "    \"google/gemini-pro-1.5\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "    \"google/gemini-flash-1.5-8b\",\n",
    "\n",
    "    \"meta-llama/llama-4-maverick\",\n",
    "    \"meta-llama/llama-4-scout\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-405b-instruct\", # 83% approval rate\n",
    "    \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"meta-llama/llama-3-70b-instruct\",\n",
    "    \"meta-llama/llama-3-8b-instruct\",\n",
    "    # \"meta-llama/llama-2-70b-chat\", # no valid responses in early stages\n",
    "\n",
    "    # \"anthropic/claude-3.7-sonnet:beta\", # not run\n",
    "    # \"anthropic/claude-3.5-sonnet:beta\", # not run\n",
    "    \"anthropic/claude-3.5-sonnet-20240620:beta\",\n",
    "    \"anthropic/claude-3.5-haiku:beta\",\n",
    "    # \"anthropic/claude-3-sonnet:beta\", # not run\n",
    "    # \"anthropic/claude-3-haiku:beta\", # 79% approval rate\n",
    "\n",
    "    \"microsoft/phi-4\",\n",
    "    # \"microsoft/phi-3.5-mini-128k-instruct\", # not run\n",
    "    # \"microsoft/phi-3-medium-128k-instruct\", # 89% approval rate\n",
    "    # \"microsoft/phi-3-mini-128k-instruct\", # 88% approval rate\n",
    "\n",
    "    \"qwen/qwen-max\",\n",
    "    \"qwen/qwen-plus\",\n",
    "    \"qwen/qwen-turbo\",\n",
    "\n",
    "    \"qwen/qwen3-32b:nothink\",\n",
    "    \"qwen/qwen3-30b-a3b:nothink\",\n",
    "\n",
    "    \"qwen/qwen-2.5-72b-instruct\",\n",
    "    \"qwen/qwen-2.5-7b-instruct\",\n",
    "    \"qwen/qwen-2-72b-instruct\",\n",
    "\n",
    "    \"qwen/qwen3-32b:nothink\",\n",
    "    \"qwen/qwen3-30b-a3b:nothink\",\n",
    "\n",
    "    \"deepseek/deepseek-chat\",\n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "    # \"deepseek/deepseek-prover-v2\", # not run\n",
    "\n",
    "    \"google/gemma-3-27b-it\",\n",
    "    \"google/gemma-3-12b-it\",\n",
    "    \"google/gemma-3-4b-it\",\n",
    "\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "\n",
    "    # \"cohere/command-r\", # rate limits\n",
    "    # \"cohere/command-r-plus\",  # not run\n",
    "\n",
    "    # \"mistralai/mixtral-8x22b-instruct\", # low approval rate\n",
    "    \"mistralai/mixtral-8x7b-instruct\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.3\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.1\",\n",
    "\n",
    "    \"mistralai/mistral-large-2407\",\n",
    "    \"mistralai/mistral-large\",\n",
    "    \"mistralai/mistral-small\",\n",
    "    \"mistralai/mistral-nemo\",\n",
    "\n",
    "    \"amazon/nova-micro-v1\",\n",
    "    \"amazon/nova-lite-v1\",\n",
    "    \"amazon/nova-pro-v1\",\n",
    "]\n",
    "\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/all_model_runs/\"\n",
    "# RESULTS_DIR = \"data/20250507/test/\"\n",
    "# RESULTS_DIR = \"data/20250507/reasoning_model_runs/\"\n",
    "# RESULTS_DIR = \"data/20250507/paraphrase_model_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36934e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    \"s4\",\n",
    "    \"s5\",\n",
    "]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    continue_to_next_model = False\n",
    "    for exp in exps:\n",
    "        dr = DilemmaRunner(\n",
    "            model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            override_decision_temperature=1.0,  # default 0.0\n",
    "            # prompts_template='reasoning_after',\n",
    "            # prompts_template='no_reasoning',\n",
    "            choices_filename=\"choices_672.csv\",\n",
    "        )\n",
    "        await dr.run(\n",
    "            # limit=10,\n",
    "            # disable_validation=True,\n",
    "            try_retries=False\n",
    "        )\n",
    "        # dr.process()\n",
    "\n",
    "        # valid_pct = (dr.data.raw_response.str.len() != 0).sum() / len(dr.data)\n",
    "    #     if valid_pct < 0.85:\n",
    "    #         print(f\"Warning: {valid_pct:.2%} of responses for model {decision_model_id} are empty.\")\n",
    "    #         continue_to_next_model = True\n",
    "    #     if continue_to_next_model:\n",
    "    #         continue\n",
    "    # if continue_to_next_model:\n",
    "    #     print(f\"Finished decision model {decision_model_id}.\\n\\n\")\n",
    "    #     continue\n",
    "    print(f\"Finished decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f947c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    \"s4\",\n",
    "    \"s5\",\n",
    "]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33537951",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model_ids = [\n",
    "    # # # HuggingFace # # #\n",
    "    \"Qwen2.5-32B-Instruct\",\n",
    "    \"Qwen2.5-14B-Instruct\",\n",
    "    \"Qwen2.5-3B-Instruct\",\n",
    "    \"Qwen2.5-1.5B-Instruct\",\n",
    "\n",
    "    \"Qwen1.5-72B-Chat\",\n",
    "    \"Qwen1.5-32B-Chat\",\n",
    "    \"Qwen1.5-14B-Chat\",\n",
    "    \"Qwen1.5-7B-Chat\",\n",
    "    \"Qwen1.5-4B-Chat\",\n",
    "\n",
    "    # \"google/gemma-3-1b-it\", # not run\n",
    "]\n",
    "\n",
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    \"s4\",\n",
    "    \"s5\",\n",
    "]\n",
    "for decision_model_id in hf_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601bbdb",
   "metadata": {},
   "source": [
    "## Reasoning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fa0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_model_ids = [\n",
    "    # # # Reasoning Models # # #\n",
    "    \"qwen/qwq-32b\",\n",
    "\n",
    "    \"qwen/qwen3-32b:think\",\n",
    "    \"qwen/qwen3-30b-a3b:think\",\n",
    "\n",
    "    \"deepseek/deepseek-r1\",\n",
    "    \"deepseek/deepseek-r1-distill-llama-70b\",\n",
    "    \"deepseek/deepseek-r1-distill-llama-8b\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/reasoning_model_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    \"s4\",\n",
    "    \"s5\",\n",
    "]\n",
    "for decision_model_id in reasoning_model_ids:\n",
    "    for exp in exps:\n",
    "        dr = DilemmaRunner(\n",
    "            model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            # override_decision_temperature=0.0,  # default\n",
    "            # prompts_template='reasoning_after',\n",
    "            prompts_template='no_reasoning',\n",
    "            choices_filename=\"choices_672.csv\",\n",
    "        )\n",
    "        await dr.run(\n",
    "            # limit=10,\n",
    "            # disable_validation=True,\n",
    "            try_retries=False\n",
    "        )\n",
    "    print(f\"Finished decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    \"s4\",\n",
    "    \"s5\",\n",
    "]\n",
    "for decision_model_id in reasoning_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd776e",
   "metadata": {},
   "source": [
    "## SFT-DPO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42027cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sftdpo_model_ids = [\n",
    "    \"amd/Instella-3B-SFT\",\n",
    "    \"amd/Instella-3B-Instruct\",\n",
    "\n",
    "    \"OLMo-2-0325-32B-SFT\",\n",
    "    \"OLMo-2-0325-32B-DPO\",\n",
    "    \"OLMo-2-0325-32B-Instruct\",\n",
    "\n",
    "    \"OLMo-2-1124-13B-SFT\",\n",
    "    \"OLMo-2-1124-13B-DPO\",\n",
    "    \"OLMo-2-1124-13B-Instruct\",\n",
    "\n",
    "    \"Llama-3.1-Tulu-3-70B-SFT\",\n",
    "    \"Llama-3.1-Tulu-3-70B-DPO\",\n",
    "    \"Llama-3.1-Tulu-3-70B\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/dpo_model_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ac94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run decision models on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc70d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "for decision_model_id in sftdpo_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e045d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_model_ids = [\n",
    "    \"allenai/tulu-2-13b\",\n",
    "\n",
    "    \"allenai/tulu-v2.5-dpo-13b-uf-mean\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-helpsteer\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-shp2\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-stackexchange\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-uf-overall\", # not run\n",
    "    \"allenai/tulu-v2.5-dpo-13b-capybara\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-prm-phase-2\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-hh-rlhf\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-nectar\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-chatbot-arena-2023\", # not run\n",
    "    \"allenai/tulu-v2.5-dpo-13b-chatbot-arena-2024\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-alpacafarm-human-pref\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-alpacafarm-gpt4-pref\",\n",
    "    \"allenai/tulu-v2.5-dpo-13b-argilla-orca-pairs\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/preference_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run decision models on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33652a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "for decision_model_id in preference_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ab5d3",
   "metadata": {},
   "source": [
    "## Paraphrase Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model_ids = [\n",
    "    \"gpt-4o-2024-11-20\",\n",
    "    \"gpt-4o-mini-2024-07-18\",\n",
    "    \"gpt-3.5-turbo-0125\",\n",
    "\n",
    "    \"google/gemini-pro-1.5\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "\n",
    "    \"meta-llama/llama-4-maverick\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "\n",
    "    \"mistralai/mistral-nemo\",\n",
    "    \"mistralai/mistral-large\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-11-20\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/paraphrase_model_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "para_idxs = [1, 2, 3]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    continue_to_next_model = False\n",
    "    for exp in exps:\n",
    "        for para_idx in para_idxs:\n",
    "            dr = DilemmaRunner(\n",
    "                model_id=decision_model_id,\n",
    "                decision_run_name=f\"{exp}-{para_idx}\",\n",
    "                results_dir=RESULTS_DIR,\n",
    "                override_decision_temperature=1.0,  # default 0.0\n",
    "                # prompts_template='reasoning_after',\n",
    "                # prompts_template='no_reasoning',\n",
    "                choices_filename=\"choices_672.csv\",\n",
    "                paraphrase_idx=para_idx,\n",
    "            )\n",
    "            await dr.run(\n",
    "                # limit=10,\n",
    "                # disable_validation=True,\n",
    "                try_retries=False\n",
    "            )\n",
    "    print(f\"Finished decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "para_idxs = [1, 2, 3]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    for exp in exps:\n",
    "        for para_idx in para_idxs:\n",
    "            jr = JudgeRunner(\n",
    "                decision_model_id=decision_model_id,\n",
    "                decision_run_name=f\"{exp}-{para_idx}\",\n",
    "                judge_model_id=judge_model_ids[0],\n",
    "                judge_run_name=f\"{exp}-{para_idx}\",\n",
    "                results_dir=RESULTS_DIR,\n",
    "                judge_cot=True,\n",
    "                override_judge_temperature=0.0,\n",
    "            )\n",
    "            await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d6d30",
   "metadata": {},
   "source": [
    "## Judge Model Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38057ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model_ids = [\n",
    "    \"gpt-4o-2024-11-20\",\n",
    "    \"gpt-4o-mini-2024-07-18\",\n",
    "    \"gpt-3.5-turbo-0125\",\n",
    "\n",
    "    \"google/gemini-pro-1.5\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "\n",
    "    \"meta-llama/llama-4-maverick\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "\n",
    "    \"mistralai/mistral-nemo\",\n",
    "    \"mistralai/mistral-large\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    \"gpt-4.1-mini-2025-04-14\",\n",
    "    \"gpt-4o-2024-11-20\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/judge_model_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, copy over relevant (above) model response files (all five samples) from\n",
    "# `data/20250507/all_model_runs/responses` to `data/20250507/judge_model_runs/responses`\n",
    "# if we don't want to run the decision models over again.\n",
    "\n",
    "# exps = [\n",
    "#     \"s1\",\n",
    "#     \"s2\",\n",
    "#     \"s3\",\n",
    "#     \"s4\",\n",
    "#     \"s5\",\n",
    "# ]\n",
    "# for decision_model_id in decision_model_ids:\n",
    "#     continue_to_next_model = False\n",
    "#     for exp in exps:\n",
    "#         for para_idx in para_idxs:\n",
    "#             dr = DilemmaRunner(\n",
    "#                 model_id=decision_model_id,\n",
    "#                 decision_run_name=f\"{exp}\",\n",
    "#                 results_dir=RESULTS_DIR,\n",
    "#                 override_decision_temperature=1.0,  # default 0.0\n",
    "#                 # prompts_template='reasoning_after',\n",
    "#                 # prompts_template='no_reasoning',\n",
    "#                 choices_filename=\"choices_672.csv\",\n",
    "#             )\n",
    "#             await dr.run(\n",
    "#                 # limit=10,\n",
    "#                 # disable_validation=True,\n",
    "#                 try_retries=False\n",
    "#             )\n",
    "#     print(f\"Finished decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    \"s2\",\n",
    "    \"s3\",\n",
    "    \"s4\",\n",
    "    \"s5\",\n",
    "]\n",
    "for judge_model_id in judge_model_ids:\n",
    "    for decision_model_id in decision_model_ids:\n",
    "        for exp in exps:\n",
    "            for para_idx in para_idxs:\n",
    "                jr = JudgeRunner(\n",
    "                    decision_model_id=decision_model_id,\n",
    "                    decision_run_name=f\"{exp}\",\n",
    "                    judge_model_id=judge_model_id,\n",
    "                    judge_run_name=f\"{exp}\",\n",
    "                    results_dir=RESULTS_DIR,\n",
    "                    judge_cot=True,\n",
    "                    override_judge_temperature=0.0,\n",
    "                )\n",
    "                await jr.run_rationales()\n",
    "\n",
    "        print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952afd6",
   "metadata": {},
   "source": [
    "## Reasoning after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_model_ids = [\n",
    "    # # # Standard Models # # #\n",
    "    \"gpt-4.1-2025-04-14\",\n",
    "    \"gpt-4.1-mini-2025-04-14\",\n",
    "    \"gpt-4.1-nano-2025-04-14\",\n",
    "    \"gpt-4o-2024-11-20\",\n",
    "    \"gpt-4o-2024-08-06\",\n",
    "    \"gpt-4o-2024-05-13\",\n",
    "    \"gpt-4o-mini-2024-07-18\",\n",
    "    \"gpt-3.5-turbo-0125\",\n",
    "    \"gpt-3.5-turbo-1106\",\n",
    "\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    \"google/gemini-2.0-flash-001\",\n",
    "    \"google/gemini-2.0-flash-lite-001\",\n",
    "    \"google/gemini-pro-1.5\",\n",
    "    \"google/gemini-flash-1.5\",\n",
    "    \"google/gemini-flash-1.5-8b\",\n",
    "\n",
    "    \"meta-llama/llama-4-maverick\",\n",
    "    \"meta-llama/llama-4-scout\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"meta-llama/llama-3-70b-instruct\",\n",
    "    \"meta-llama/llama-3-8b-instruct\",\n",
    "\n",
    "    \"anthropic/claude-3.5-sonnet-20240620:beta\",\n",
    "    \"anthropic/claude-3.5-haiku:beta\",\n",
    "\n",
    "    \"microsoft/phi-4\",\n",
    "\n",
    "    \"qwen/qwen-max\",\n",
    "    \"qwen/qwen-plus\",\n",
    "    \"qwen/qwen-turbo\",\n",
    "\n",
    "    \"qwen/qwen3-32b:nothink\",\n",
    "    \"qwen/qwen3-30b-a3b:nothink\",\n",
    "\n",
    "    \"qwen/qwen-2.5-72b-instruct\",\n",
    "    \"qwen/qwen-2.5-7b-instruct\",\n",
    "    \"qwen/qwen-2-72b-instruct\",\n",
    "\n",
    "    \"qwen/qwen3-32b:nothink\",\n",
    "    \"qwen/qwen3-30b-a3b:nothink\",\n",
    "\n",
    "    \"deepseek/deepseek-chat\",\n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "\n",
    "    \"google/gemma-3-27b-it\",\n",
    "    \"google/gemma-3-12b-it\",\n",
    "    \"google/gemma-3-4b-it\",\n",
    "\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "\n",
    "    \"mistralai/mixtral-8x7b-instruct\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.3\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.1\",\n",
    "\n",
    "    \"mistralai/mistral-large-2407\",\n",
    "    \"mistralai/mistral-large\",\n",
    "    \"mistralai/mistral-small\",\n",
    "    \"mistralai/mistral-nemo\",\n",
    "\n",
    "    \"amazon/nova-micro-v1\",\n",
    "    \"amazon/nova-lite-v1\",\n",
    "    \"amazon/nova-pro-v1\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview-04-17\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/reasoning_after_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"after1\",\n",
    "    \"after2\",\n",
    "    \"after3\",\n",
    "    \"after4\",\n",
    "    \"after5\",\n",
    "]\n",
    "for decision_model_id in after_model_ids:\n",
    "    continue_to_next_model = False\n",
    "    for exp in exps:\n",
    "        dr = DilemmaRunner(\n",
    "            model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            override_decision_temperature=1.0,  # default 0.0\n",
    "            prompts_template='reasoning_after',\n",
    "            # prompts_template='no_reasoning',\n",
    "            choices_filename=\"choices_672.csv\",\n",
    "        )\n",
    "        await dr.run(\n",
    "            # limit=10,\n",
    "            # disable_validation=True,\n",
    "            # overwrite=True,\n",
    "            try_retries=False,\n",
    "        )\n",
    "        # dr.process()\n",
    "    print(f\"Finished decision model {decision_model_id}.\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"after1\",\n",
    "    \"after2\",\n",
    "    \"after3\",\n",
    "    \"after4\",\n",
    "    \"after5\",\n",
    "]\n",
    "for decision_model_id in after_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales()\n",
    "\n",
    "    print(f\"Finished analyzing decision model {decision_model_id}.\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moral2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
