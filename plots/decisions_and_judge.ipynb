{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc787a0c",
   "metadata": {},
   "source": [
    "## Query models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7719ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from moral_lens.dilemma import DilemmaRunner\n",
    "from moral_lens.judge import JudgeRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model_ids = [\n",
    "    # # # RQ1 # # #\n",
    "    # \"gpt-4.1-2025-04-14\",\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4.1-nano-2025-04-14\",\n",
    "    # \"gpt-4o-2024-11-20\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    # \"gpt-4o-2024-05-13\",\n",
    "    # \"gpt-4o-mini-2024-07-18\",\n",
    "    # \"gpt-3.5-turbo-0125\",\n",
    "    # \"gpt-3.5-turbo-1106\",\n",
    "\n",
    "    # \"google/gemini-2.5-flash-preview\",\n",
    "    # \"google/gemini-2.0-flash-001\",\n",
    "    # \"google/gemini-2.0-flash-lite-001\",\n",
    "    # \"google/gemini-pro-1.5\",\n",
    "    # \"google/gemini-flash-1.5\",\n",
    "    # \"google/gemini-flash-1.5-8b\",\n",
    "\n",
    "    # \"meta-llama/llama-4-maverick\",\n",
    "    # \"meta-llama/llama-4-scout\",\n",
    "    # \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-405b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    # \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    # \"meta-llama/llama-3-70b-instruct\",\n",
    "    # \"meta-llama/llama-3-8b-instruct\",\n",
    "\n",
    "    # \"anthropic/claude-3.7-sonnet:beta\",\n",
    "    # \"anthropic/claude-3.5-sonnet:beta\",\n",
    "    # \"anthropic/claude-3.5-sonnet-20240620:beta\",\n",
    "    # \"anthropic/claude-3.5-haiku:beta\",\n",
    "    # \"anthropic/claude-3-sonnet:beta\",\n",
    "    # \"anthropic/claude-3-haiku:beta\",\n",
    "\n",
    "    # \"microsoft/phi-4\",\n",
    "    # \"microsoft/phi-3.5-mini-128k-instruct\",\n",
    "    # \"microsoft/phi-3-medium-128k-instruct\",\n",
    "    # \"microsoft/phi-3-mini-128k-instruct\",\n",
    "\n",
    "    # \"qwen/qwen-turbo\",\n",
    "    # \"qwen/qwen-plus\",\n",
    "    # \"qwen/qwen-max\",\n",
    "\n",
    "    # \"qwen/qwen-2.5-7b-instruct\",\n",
    "    # \"qwen/qwen-2.5-72b-instruct\",\n",
    "\n",
    "    # \"google/gemma-3-4b-it\",\n",
    "    # \"google/gemma-3-12b-it\",\n",
    "    # \"google/gemma-3-27b-it\",\n",
    "\n",
    "    # # # RQ2 # # #\n",
    "    # \"OLMo-2-0325-32B-SFT\",\n",
    "    # \"OLMo-2-0325-32B-DPO\",\n",
    "    # \"OLMo-2-0325-32B-Instruct\",\n",
    "\n",
    "    # \"OLMo-2-1124-13B-SFT\",\n",
    "    # \"OLMo-2-1124-13B-DPO\",\n",
    "    # \"OLMo-2-1124-13B-Instruct\",\n",
    "\n",
    "    # \"Llama-3.1-Tulu-3-70B-SFT\",\n",
    "    # \"Llama-3.1-Tulu-3-70B-DPO\",\n",
    "    # \"Llama-3.1-Tulu-3-70B\",\n",
    "\n",
    "    # # # RQ3 # # #\n",
    "    # \"tulu-v2.5-dpo-13b-hh-rlhf-60k\",\n",
    "    # \"tulu-v2.5-dpo-13b-chatbot-arena-2023\",\n",
    "    # \"tulu-v2.5-dpo-13b-stackexchange-60k\",\n",
    "    # \"tulu-v2.5-dpo-13b-nectar-60k\",\n",
    "\n",
    "    # \"tulu-v2.5-ppo-13b-hh-rlhf-60k\",\n",
    "    # \"tulu-v2.5-ppo-13b-chatbot-arena-2023\",\n",
    "    # \"tulu-v2.5-ppo-13b-stackexchange-60k\",\n",
    "    # \"tulu-v2.5-ppo-13b-nectar-60k\",\n",
    "\n",
    "    # \"allenai/tulu-2-13b\",\n",
    "\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-uf-mean\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-helpsteer\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-shp2\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-stackexchange\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-uf-overall\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-capybara\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-prm-phase-2\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-hh-rlhf\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-nectar\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-chatbot-arena-2023\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-chatbot-arena-2024\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-alpacafarm-human-pref\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-alpacafarm-gpt4-pref\",\n",
    "    # \"allenai/tulu-v2.5-dpo-13b-argilla-orca-pairs\",\n",
    "\n",
    "    # # RQ4 # # #\n",
    "    # \"qwen/qwq-32b\",\n",
    "    # \"qwen/qwen-max\",\n",
    "\n",
    "    # \"deepseek/deepseek-chat\",\n",
    "    # \"deepseek/deepseek-chat-v3-0324\",\n",
    "    # \"deepseek/deepseek-r1\",\n",
    "    # \"deepseek/deepseek-r1-distill-llama-70b\",\n",
    "]\n",
    "judge_model_ids = [\n",
    "    # \"gpt-4.1-mini-2025-04-14\",\n",
    "    # \"gpt-4o-2024-08-06\",\n",
    "    \"google/gemini-2.5-flash-preview\",\n",
    "    # \"gemini-2.5-flash-preview-04-17\",\n",
    "]\n",
    "RESULTS_DIR = \"data/20250507/all_model_runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36934e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    # \"s1\",\n",
    "    \"s2\",\n",
    "    # \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    for exp in exps:\n",
    "        dr = DilemmaRunner(\n",
    "            model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            override_decision_temperature=1.0,  # default 0.0\n",
    "            # prompts_template='reasoning_after',\n",
    "            # prompts_template='no_reasoning',\n",
    "            choices_filename=\"choices_672.csv\",\n",
    "        )\n",
    "        await dr.run(overwrite=True)\n",
    "        # dr.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeec6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    \"s1\",\n",
    "    # \"s2\",\n",
    "    # \"s3\",\n",
    "    # \"s4\",\n",
    "    # \"s5\",\n",
    "]\n",
    "for decision_model_id in decision_model_ids:\n",
    "    for exp in exps:\n",
    "        jr = JudgeRunner(\n",
    "            decision_model_id=decision_model_id,\n",
    "            decision_run_name=exp,\n",
    "            judge_model_id=judge_model_ids[0],\n",
    "            judge_run_name=exp,\n",
    "            results_dir=RESULTS_DIR,\n",
    "            judge_cot=True,\n",
    "            override_judge_temperature=0.0,\n",
    "        )\n",
    "        await jr.run_rationales(overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moral2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
